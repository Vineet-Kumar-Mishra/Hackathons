{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Run all the cells","metadata":{}},{"cell_type":"code","source":"# ! pip install albumentations\nfrom PIL import Image\nimport os\nimport sys\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom tqdm import tqdm_notebook\nfrom torchvision.utils import save_image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Change Batch and Num_epochs according to the compute power","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/gan-getting-started'\nDevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBatch = 10\nLearning_rate = 1e-5\nLambda_identity = 5\nLambda_cycle = 10\nNum_workers = 4\nNum_epochs = 6\nLoad_model = True\nSave_model = True\ntransforms = A.Compose([A.Resize(width = 256, height = 256),\n                       A.HorizontalFlip(p=0.5),\n                       A.Normalize(mean=[0.5,0.5,0.5], std = [0.5,0.5,0.5], max_pixel_value = 255),\n                       ToTensorV2()], additional_targets = {'image0':'image'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cutom Dataset","metadata":{}},{"cell_type":"code","source":"class monet_dataset(Dataset):\n    def __init__(self, root_img, root_monet, transform=None):\n        self.root_img = root_img\n        self.root_monet = root_monet\n        self.transform = transform\n        \n        self.img_images = os.listdir(root_img)\n        self.monet_images = os.listdir(root_monet)\n        self.length_dataset = max(len(self.img_images), len(self.monet_images))\n        self.img_len = len(self.img_images)\n        self.monet_len = len(self.monet_images)\n        \n    def __len__(self):\n        return self.length_dataset\n    \n    def __getitem__(self, index):\n        img_image = self.img_images[index%self.img_len]\n        monet_image = self.monet_images[index%self.monet_len]\n        \n        img_path = os.path.join(self.root_img,img_image)\n        monet_path = os.path.join(self.root_monet, monet_image)\n        \n        img_image = np.array(Image.open(img_path).convert(\"RGB\"))\n        monet_image = np.array(Image.open(monet_path).convert(\"RGB\"))\n        \n        if self.transform:\n            aug = self.transform(image=img_image, image0=monet_image)\n            img_image = aug[\"image\"]\n            monet_image = aug[\"image0\"]\n            \n        return img_image, monet_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generator model for cycle Gan","metadata":{}},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n            if down\n            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True) if use_act else nn.Identity()\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.block = nn.Sequential(\n            ConvBlock(channels, channels, kernel_size=3, padding=1),\n            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\nclass Generator(nn.Module):\n    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n            nn.InstanceNorm2d(num_features),\n            nn.ReLU(inplace=True),\n        )\n        self.down_blocks = nn.ModuleList(\n            [\n                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n            ]\n        )\n        self.res_blocks = nn.Sequential(\n            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n        )\n        self.up_blocks = nn.ModuleList(\n            [\n                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n            ]\n        )\n\n        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n\n    def forward(self, x):\n        x = self.initial(x)\n        for layer in self.down_blocks:\n            x = layer(x)\n        x = self.res_blocks(x)\n        for layer in self.up_blocks:\n            x = layer(x)\n        return torch.tanh(self.last(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Discriminator for Cycle Gan","metadata":{}},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                features[0],\n                kernel_size=4,\n                stride=2,\n                padding=1,\n                padding_mode=\"reflect\",\n            ),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        layers = []\n        in_channels = features[0]\n        for feature in features[1:]:\n            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))\n            in_channels = feature\n        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.initial(x)\n        return torch.sigmoid(self.model(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to train the models once !","metadata":{}},{"cell_type":"code","source":"def train_fn(disc_i, disc_m, gen_m, gen_i,loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler,epoch):\n    m_reals = 0\n    m_fakes = 0\n    loop = tqdm_notebook(loader, leave=True)\n    \n    for idx, (img,monet) in enumerate(loop):\n        img = img.to(Device)\n        monet = monet.to(Device)\n        \n        \n        with torch.cuda.amp.autocast():\n            fake_monet = gen_m(img)\n            D_M_real = disc_m(monet)\n            D_M_fake = disc_m(fake_monet.detach())\n            m_reals += D_M_real.mean().item()\n            m_fakes +=D_M_fake.mean().item()\n            D_M_real_loss = mse(D_M_real, torch.ones_like(D_M_real))\n            D_M_fake_loss = mse(D_M_fake, torch.ones_like(D_M_fake))\n            D_M_loss = D_M_fake_loss+D_M_real_loss\n            \n            fake_img = gen_i(monet)\n            D_I_real = disc_i(img)\n            D_I_fake = disc_i(fake_img.detach())\n            D_I_fake_loss = mse(D_I_fake, torch.ones_like(D_I_fake))\n            D_I_real_loss = mse(D_I_real, torch.ones_like(D_I_real))\n            D_I_loss = D_I_real_loss+D_I_fake_loss\n            \n            D_loss = (D_I_loss+D_M_loss)/2\n            \n        opt_disc.zero_grad()\n        d_scaler.scale(D_loss).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n        \n        with torch.cuda.amp.autocast():\n            D_M_fake = disc_i(fake_monet)\n            D_I_fake = disc_m(fake_img)\n            loss_G_M = mse(D_M_fake, torch.ones_like(D_M_fake))\n            loss_G_I = mse(D_I_fake, torch.ones_like(D_I_fake))\n            \n            cycle_monet = gen_m(fake_img)\n            cycle_img = gen_i(fake_monet)\n            \n            cycle_monet_loss = l1(monet, cycle_monet)\n            cycle_img_loss = l1(img, cycle_img)\n            \n            identity_monet = gen_m(monet)\n            identity_img = gen_i(img)\n            identity_monet_loss = l1(monet, identity_monet)\n            identity_img_loss = l1(img, identity_img)\n            \n            G_loss = (\n            loss_G_I+loss_G_M+\n            cycle_img_loss*Lambda_cycle+\n            cycle_monet_loss*Lambda_cycle+\n            identity_img_loss*Lambda_identity+\n            identity_monet_loss*Lambda_identity)\n            \n        opt_gen.zero_grad()\n        g_scaler.scale(G_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n        \n        if idx % 100 == 0:\n            save_image(fake_img*0.5+0.5, f\"saved_images/photo_{epoch}_{idx}.png\")\n            save_image(fake_monet*0.5+0.5, f\"saved_images/monet_{epoch}_{idx}.png\")\n        if idx%500==0:\n            torch.save(gen_i,f'Generator_img_{epoch}.pth')\n            torch.save(gen_m,f'Generator_monet_{epoch}.pth')\n            torch.save(disc_i,f'Discriminator_img_{epoch}.pth')\n            torch.save(disc_m,f'Discriminator_monet_{epoch}.pth')\n\n        loop.set_postfix(m_real=m_reals/(idx+1), m_fake=m_fakes/(idx+1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making instance of generators and discriminators outside the main function\n# Main function loads the dataset and trains the models for Num_epochs","metadata":{}},{"cell_type":"code","source":"disc_I = Discriminator(in_channels=3).to(Device)\ndisc_M = Discriminator(in_channels=3).to(Device)\ngen_M = Generator(img_channels=3).to(Device)\ngen_I = Generator(img_channels=3).to(Device)\n\ndef main(disc_I, disc_M, gen_M, gen_I):\n    disc_I = disc_I\n    disc_M = disc_M\n    gen_M = gen_M\n    gen_I = gen_I\n    opt_disc = optim.Adam(\n        list(disc_I.parameters()) + list(disc_M.parameters()),\n        lr=Learning_rate,\n        betas=(0.5, 0.999),\n    )\n\n    opt_gen = optim.Adam(\n        list(gen_I.parameters()) + list(gen_M.parameters()),\n        lr=Learning_rate,\n        betas=(0.5, 0.999),\n    )\n    \n    L1 = nn.L1Loss()\n    mse = nn.MSELoss()\n    \n    dataset = monet_dataset(root_img=os.path.join(data_dir,\"photo_jpg\"),\n                            root_monet=os.path.join(data_dir,\"monet_jpg\"),\n                           transform = transforms)\n    \n    loader = DataLoader(dataset, batch_size=Batch, shuffle=True, pin_memory = True) # num_workers=Num_workers,\n    g_scaler = torch.cuda.amp.GradScaler()\n    d_scaler = torch.cuda.amp.GradScaler()\n    \n    for epoch in range(Num_epochs):\n        train_fn(disc_I, disc_M, gen_M, gen_I, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler,epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating directory to save images and running the main function","metadata":{}},{"cell_type":"code","source":"if not os.path.exists('saved_images'):\n    os.makedirs('saved_images')\nmain(disc_I, disc_M, gen_M, gen_I)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Note : I was able to run it for 15 epochs so I load the weight of 15th epoch (in this case 14)","metadata":{}},{"cell_type":"code","source":"gen_M = Generator(img_channels=3).to(Device)\ngen_M = torch.load('saved_models/Generator_monet_14.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking number of files in photo_jpg directory","metadata":{}},{"cell_type":"code","source":"photo_dir = os.path.join(data_dir,\"photo_jpg\")\nfiles = [os.path.join(photo_dir, name) for name in os.listdir(photo_dir)]\nprint(\"Number of files found\",len(files))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating a dataloder with batchsize = 1 to save the results","metadata":{}},{"cell_type":"code","source":"transforms = A.Compose([A.Normalize(mean=[0.5,0.5,0.5], std = [0.5,0.5,0.5], max_pixel_value = 255),\n                       ToTensorV2()], additional_targets = {'image0':'image'})\ndataset = monet_dataset(root_img=os.path.join(data_dir,\"photo_jpg\"),\n                            root_monet=os.path.join(data_dir,\"monet_jpg\"),\n                           transform = transforms)\n    \nloader = DataLoader(dataset, batch_size=1, shuffle=True, pin_memory = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating the monet images from photos and saving them individually !","metadata":{}},{"cell_type":"code","source":"loop = tqdm_notebook(loader, leave=True)\nfor idx, (img,_) in enumerate(loop):\n    img = img.to(Device)\n    monet = gen_M(img).detach().cpu()\n    monet = monet*0.5+0.5\n    save_image(monet, f\"generated_images/photo_to_monet_{idx}.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Zipping the contents","metadata":{}},{"cell_type":"code","source":"import shutil\nshutil.make_archive('generated_images', 'zip','generated_images')","metadata":{},"execution_count":null,"outputs":[]}]}